## Superexpressive Ativações e o Teorema da Superposição de Kolmogorov

### Introdução
Após demonstrar a capacidade de aproximação universal das redes neurais com funções de ativação de uma ampla classe, surge a questão sobre o tamanho necessário da rede para atingir uma precisão específica. Os resultados anteriores não forneceram *insights* sobre o tamanho da rede neural necessária para atingir uma determinada acurácia. Este capítulo explora um resultado notável que demonstra como a escolha da função de ativação influencia significativamente o tamanho da rede neural. Apresentaremos a Proposição 3.19 [^11], que estabelece que, com uma função de ativação apropriada, toda função contínua $f \in C^0(K)$ em um conjunto compacto $K \subseteq \mathbb{R}^d$ pode ser aproximada com qualquer precisão desejada $\epsilon > 0$ usando uma rede neural de tamanho $O(d^2)$. Em particular, o tamanho da rede neural é independente de $\epsilon$, $K$ e $f$ [^11]. Inicialmente, discutiremos o caso unidimensional e, posteriormente, generalizaremos para dimensões superiores utilizando o Teorema da Superposição de Kolmogorov [^11].

### Conceitos Fundamentais

**Proposição 3.19** [^11]: *Existe uma função de ativação contínua $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ tal que, para todo conjunto compacto $K \subseteq \mathbb{R}$, todo $\epsilon > 0$ e toda $f \in C^0(K)$, existe $\Phi(x) = \sigma(wx + b) \in N_1(\sigma; 1, 1)$ tal que*
$$
\sup_{x \in K} |f(x) - \Phi(x)| < \epsilon.
$$
Esta proposição implica que com uma função de ativação apropriada, toda função contínua pode ser aproximada com qualquer precisão desejada.

*Demonstração*:
Seja $P_n$ o conjunto de todos os polinômios $p(x) = \sum_{j=0}^n q_j x^j$ com coeficientes racionais, ou seja, $q_j \in \mathbb{Q}$ para todo $j = 0, ..., n$ [^11]. Então, $P_n$ pode ser identificado com o produto cartesiano $n$-dimensional $\mathbb{Q} \times ... \times \mathbb{Q}$, e, portanto, $P_n$ é um conjunto enumerável [^11]. Consequentemente, o conjunto $P := \bigcup_{n \in \mathbb{N}} P_n$ de todos os polinômios com coeficientes racionais também é enumerável [^11]. Seja $(p_i)_{i \in \mathbb{Z}}$ uma enumeração desses polinômios e defina:
$$
\sigma(x) :=
\begin{cases}
p_i(x - 2i) & \text{se } x \in [2i, 2i + 1] \\
p_i(1)(2i + 2 - x) + p_{i+1}(0)(x - 2i - 1) & \text{se } x \in (2i + 1, 2i + 2).
\end{cases}
$$
Em outras palavras, $\sigma$ é igual a $p_i$ em intervalos pares $[2i, 2i + 1]$ e é linear em intervalos ímpares $[2i + 1, 2i + 2]$, resultando em uma função contínua [^11].

Primeiramente, assumimos $K = [0, 1]$ [^11]. Pelo Exemplo 3.5 [^5], para todo $\epsilon > 0$, existe $p(x) = \sum_{j=1}^n r_j x^j$ tal que $\sup_{x \in [0, 1]} |p(x) - f(x)| < \epsilon / 2$ [^11]. Agora, escolha $q_j \in \mathbb{Q}$ tão próximo de $r_j$ tal que $\tilde{p}(x) := \sum_{j=1}^n q_j x^j$ satisfaz $\sup_{x \in [0, 1]} |\tilde{p}(x) - p(x)| < \epsilon / 2$ [^11]. Seja $i \in \mathbb{Z}$ tal que $\tilde{p}(x) = p_i(x)$, ou seja, $p_i(x) = \sigma(x + 2i)$ para todo $x \in [0, 1]$ [^11]. Então, $\sup_{x \in [0, 1]} |f(x) - \sigma(x + 2i)| < \epsilon$ [^11].

Para um conjunto compacto geral $K$, assuma que $K \subseteq [a, b]$ [^11]. Pelo Teorema da Extensão de Tietze, $f$ admite uma extensão contínua para $[a, b]$, então, sem perda de generalidade, $K = [a, b]$ [^11]. Pelo primeiro caso, podemos encontrar $i \in \mathbb{Z}$ tal que com $y = (x - a) / (b - a)$ (i.e., $y \in [0, 1]$ se $x \in [a, b]$):
$$
\sup_{x \in [a, b]} \left|f(x) - \sigma\left(\frac{x - a}{b - a} + 2i\right)\right| = \sup_{y \in [0, 1]} |f(y \cdot (b - a) + a) - \sigma(y + 2i)| < \epsilon,
$$
o que dá a afirmação com $w = 1 / (b - a)$ e $b = -a / (b - a) + 2i$ [^11]. $\blacksquare$

Para estender esse resultado para dimensões arbitrárias, utilizaremos o Teorema da Superposição de Kolmogorov [^11].

**Teorema 3.20 (Kolmogorov)** [^12]: *Para todo $d \in \mathbb{N}$, existem funções monotonicamente crescentes $\varphi_{i,j} \in C^0(\mathbb{R})$, $i = 1, ..., d$, $j = 1, ..., 2d + 1$, tais que para toda $f \in C^0([0, 1]^d)$ existem funções $f_j \in C^0(\mathbb{R})$, $j = 1, ..., 2d + 1$ satisfazendo*
$$
f(x) = \sum_{j=1}^{2d+1} f_j \left(\sum_{i=1}^d \varphi_{i,j}(x_i) \right) \quad \text{para todo } x \in [0, 1]^d.
$$

**Corolário 3.21** [^12]: *Seja $d \in \mathbb{N}$. Com a função de ativação $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ da Proposição 3.19, para todo conjunto compacto $K \subseteq \mathbb{R}^d$, todo $\epsilon > 0$ e toda $f \in C^0(K)$, existe $\Phi \in N_1(\sigma; 2, 2d^2 + d)$ (i.e., width$(\Phi) = 2d^2 + d$ e depth$(\Phi) = 2$) tal que*
$$
\sup_{x \in K} |f(x) - \Phi(x)| < \epsilon.
$$

*Demonstração*:
Sem perda de generalidade, podemos assumir que $K = [0, 1]^d$: a extensão para o caso geral segue pelo teorema da extensão de Tietze e um argumento de escala como na demonstração da Proposição 3.19 [^12]. Sejam $f_j$, $\varphi_{i,j}$, $i = 1, ..., d$, $j = 1, ..., 2d + 1$ como no Teorema 3.20 [^12]. Fixe $\epsilon > 0$. Seja $a > 0$ tão grande que
$$
\sup_{i, j} \sup_{x \in [0, 1]} |\varphi_{i, j}(x)| \leq a.
$$
Como cada $f_j$ é uniformemente contínua no conjunto compacto $[-da, da]$, podemos encontrar $\delta > 0$ tal que
$$
\sup_{j} \sup_{\substack{|y - \tilde{y}| < \delta \\ y, \tilde{y} \leq da}} |f_j(y) - f_j(\tilde{y})| < \frac{\epsilon}{2(2d + 1)}. \qquad (3.2.1)
$$
Pela Proposição 3.19, existem $w_{i, j}$, $b_{i, j} \in \mathbb{R}$ tais que
$$
\sup_{i, j} \sup_{x \in [0, 1]} |\varphi_{i, j}(x) - \sigma(w_{i, j}x + b_{i, j})| < \frac{\delta}{d} =: \delta_{i, j}(x). \qquad (3.2.2)
$$
e $w_j$, $b_j \in \mathbb{R}$ tais que
$$
\sup_{j} \sup_{|y| \leq a + \delta} |f_j(y) - \sigma(w_j y + b_j)| < \frac{\epsilon}{2(2d + 1)} =: \tilde{f}_j(x). \qquad (3.2.3)
$$
Então, para todo $x \in [0, 1]^d$, por (3.2.2),
$$
\left| \sum_{i=1}^d \varphi_{i, j}(x_i) - \sum_{i=1}^d \tilde{\varphi}_{i, j}(x_i) \right| < \sum_{i=1}^d \frac{\delta}{d} = \delta.
$$
Assim, com
$$
y_j := \sum_{i=1}^d \varphi_{i, j}(x_i), \quad \tilde{y}_j := \sum_{i=1}^d \tilde{\varphi}_{i, j}(x_i),
$$
temos $|y_j - \tilde{y}_j| < \delta$ [^12]. Usando (3.2.1) e (3.2.3), concluímos
$$
\left| f(x) - \sum_{j=1}^{2d+1} \sigma \left( w_j \left( \sum_{i=1}^d \sigma(w_{i, j} x_i + b_{i, j}) \right) + b_j \right) \right| = \left| \sum_{j=1}^{2d+1} (f_j(y_j) - \tilde{f}_j(\tilde{y}_j)) \right|
$$
$$
\leq \sum_{j=1}^{2d+1} \left( |f_j(y_j) - f_j(\tilde{y}_j)| + |f_j(\tilde{y}_j) - \tilde{f}_j(\tilde{y}_j)| \right)
$$
$$
\leq \sum_{j=1}^{2d+1} \left( \frac{\epsilon}{2(2d + 1)} + \frac{\epsilon}{2(2d + 1)} \right) = \epsilon.
$$
Isto conclui a demonstração [^12]. $\blacksquare$

### Conclusão
O Teorema da Superposição de Kolmogorov é intrigante, pois mostra que a aproximação de funções $d$-dimensionais pode ser reduzida ao caso (geralmente muito mais simples) unidimensional por meio de composições [^13]. As redes neurais, por natureza, são adequadas para aproximar funções com estruturas composicionais [^13]. No entanto, as funções $f_j$ no Teorema 3.20, mesmo que apenas unidimensionais, podem se tornar muito complexas e desafiadoras de aproximar se $d$ for grande [^13].

Semelhantemente, a função de ativação "mágica" na Proposição 3.19 codifica a informação de todos os polinômios racionais no intervalo unitário, razão pela qual uma rede neural de tamanho $O(1)$ é suficiente para aproximar cada função com precisão arbitrária [^13]. Naturalmente, nenhum algoritmo prático pode identificar eficientemente pesos e vieses de rede neural apropriados para essa arquitetura [^13]. Como tal, os resultados apresentados na Seção 3.2 devem ser tomados com cautela, pois sua relevância prática é altamente limitada [^13]. No entanto, eles destacam que, embora a aproximação universal seja uma propriedade fundamental e importante das redes neurais, ela deixa muitos aspectos inexplorados [^13]. Para obter mais *insights* sobre arquiteturas praticamente relevantes, nos capítulos seguintes, investigaremos redes neurais com funções de ativação como a ReLU [^13].

### Referências
[^5]: Example 3.5 (Polynomials are dense in Cº(Rd)).
[^11]: Proposition 3.19.
[^12]: Theorem 3.20 (Kolmogorov) and Corollary 3.21.
[^13]: Text after Corollary 3.21.

<!-- END -->