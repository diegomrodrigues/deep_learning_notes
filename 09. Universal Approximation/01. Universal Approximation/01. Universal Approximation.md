## O Teorema da Aproximação Universal

### Introdução
Após a introdução das redes neurais, surge naturalmente a questão sobre suas capacidades [^1]. Especificamente, podemos nos perguntar se existem limitações inerentes aos tipos de funções que uma rede neural pode representar [^1]. O teorema da aproximação universal responde a essa questão, demonstrando que redes neurais são, de fato, ferramentas universais [^1]. Este capítulo explora em detalhes esse teorema, formalizando e provando a afirmação de que, dadas arquiteturas suficientemente grandes e complexas, as redes neurais podem aproximar quase todas as relações de entrada-saída sensíveis [^1].

### Conceitos Fundamentais

**Aproximação Universal:** Refere-se à capacidade das redes neurais de aproximar virtualmente qualquer relação de entrada-saída sensível, dada complexidade e tamanho suficientes [^1]. Isso implica que elas não estão limitadas a tipos específicos de funções, como regressão linear, tornando-as ferramentas versáteis em diversas aplicações [^1].

Para analisar quais tipos de funções podem ser aproximadas com redes neurais, começamos considerando a aproximação uniforme de funções contínuas $f: \mathbb{R}^d \rightarrow \mathbb{R}$ em conjuntos compactos [^1]. Para isso, introduzimos a noção de convergência compacta [^1].

**Convergência Compacta:** Uma sequência de funções $f_n: \mathbb{R}^d \rightarrow \mathbb{R}$, $n \in \mathbb{N}$, converge compactamente para uma função $f: \mathbb{R}^d \rightarrow \mathbb{R}$, se para todo compacto $K \subseteq \mathbb{R}^d$ vale que $\lim_{n \rightarrow \infty} \sup_{x \in K} |f_n(x) - f(x)| = 0$ [^1]. Nesse caso, escrevemos $f_n \xrightarrow{CC} f$ [^1].

Consideramos sempre $C^0(\mathbb{R}^d)$ equipado com a topologia da Definição 3.1, e todo subconjunto como $C^0(D)$ com a topologia do subespaço [^1]: por exemplo, se $D \subset \mathbb{R}^d$ é limitado, então a convergência em $C^0(D)$ refere-se à convergência uniforme $\lim_{n \rightarrow \infty} \sup_{x \in D} |f_n(x) - f(x)| = 0$ [^1].

**Aproximadores Universais:** Queremos mostrar que redes neurais profundas podem aproximar toda função contínua no sentido da Definição 3.1 [^1]. Chamamos conjuntos de funções que satisfazem essa propriedade de *aproximadores universais* [^1].

**Definição 3.2:** Seja $d \in \mathbb{N}$. Um conjunto de funções $\mathcal{H}$ de $\mathbb{R}^d$ para $\mathbb{R}$ é um *aproximador universal* (de $C^0(\mathbb{R}^d)$), se para todo $\varepsilon > 0$, todo compacto $K \subset \mathbb{R}^d$, e toda $f \in C^0(\mathbb{R}^d)$, existe $g \in \mathcal{H}$ tal que $\sup_{x \in K} |f(x) - g(x)| < \varepsilon$ [^2].

Para um conjunto de funções (não necessariamente contínuas) $\mathcal{H}$ mapeando entre $\mathbb{R}^d$ e $\mathbb{R}$, denotamos por $\overline{\mathcal{H}}^{CC}$ seu fecho com respeito à convergência compacta [^2]. A relação entre um aproximador universal e o fecho com respeito à convergência compacta é estabelecida na proposição abaixo [^2].

**Proposição 3.3:** Seja $d \in \mathbb{N}$ e $\mathcal{H}$ um conjunto de funções de $\mathbb{R}^d$ para $\mathbb{R}$. Então, $\mathcal{H}$ é um aproximador universal de $C^0(\mathbb{R}^d)$ se e somente se $C^0(\mathbb{R}^d) \subseteq \overline{\mathcal{H}}^{CC}$ [^2].

*Prova:* Suponha que $\mathcal{H}$ é um aproximador universal e fixe $f \in C^0(\mathbb{R}^d)$ [^2]. Para $n \in \mathbb{N}$, defina $K_n := [-n, n]^d \subseteq \mathbb{R}^d$ [^2]. Então, para todo $n \in \mathbb{N}$ existe $f_n \in \mathcal{H}$ tal que $\sup_{x \in K_n} |f_n(x) - f(x)| < 1/n$ [^2]. Como para todo compacto $K \subseteq \mathbb{R}^d$ existe $n_0$ tal que $K \subseteq K_n$ para todo $n \geq n_0$, vale $f_n \xrightarrow{CC} f$ [^2]. A parte "somente se" da asserção é trivial [^2]. $\blacksquare$

Uma ferramenta chave para mostrar que um conjunto é um aproximador universal é o teorema de Stone-Weierstrass [^2], veja por exemplo [194, Sec. 5.7].

**Teorema 3.4 (Stone-Weierstrass):** Seja $d \in \mathbb{N}$, seja $K \subseteq \mathbb{R}^d$ compacto, e seja $\mathcal{H} \subseteq C^0(K, \mathbb{R})$ satisfazendo que [^2]:
(a) para todo $x \in K$ existe $f \in \mathcal{H}$ tal que $f(x) \neq 0$ [^2],
(b) para todo $x \neq y \in K$ existe $f \in \mathcal{H}$ tal que $f(x) \neq f(y)$ [^2],
(c) $\mathcal{H}$ é uma álgebra de funções, i.e., $\mathcal{H}$ é fechado sob adição, multiplicação e multiplicação escalar [^2].

Então $\mathcal{H}$ é denso em $C^0(K)$ [^2].

**Exemplo 3.5 (Polinômios são densos em $C^0(\mathbb{R}^d)$):** Para um multi-índice $\alpha = (\alpha_1, ..., \alpha_d) \in \mathbb{N}^d$ e um vetor $x = (x_1, ..., x_d) \in \mathbb{R}^d$ denotamos $x^\alpha := \prod_{i=1}^d x_i^{\alpha_i}$ [^2]. No que segue, com $|\alpha| := \sum_{i=1}^d \alpha_i$, escrevemos [^2]:

$$\
P_n := \text{span}\\{x^\alpha \mid \alpha \in \mathbb{N}^d, |\alpha| \leq n\\}
$$
i.e., $P_n$ é o espaço de polinômios de grau no máximo $n$ (com coeficientes reais) [^2]. É fácil verificar que $P := \bigcup_{n \in \mathbb{N}} P_n(\mathbb{R}^d)$ satisfaz as hipóteses do Teorema 3.4 em todo conjunto compacto $K \subset \mathbb{R}^d$ [^2]. Assim, o espaço de polinômios $P$ é um aproximador universal de $C^0(\mathbb{R}^d)$, e pela Proposição 3.3, $P$ é denso em $C^0(\mathbb{R}^d)$ [^2]. Caso desejemos enfatizar a dimensão do espaço subjacente, no que segue também escreveremos $P_n(\mathbb{R}^d)$ ou $P(\mathbb{R}^d)$ para denotar $P_n$, $P$ respectivamente [^2].

### Redes Neurais Rasas
Com o formalismo necessário estabelecido na subseção anterior, podemos agora demonstrar que redes neurais rasas de largura arbitrária formam um aproximador universal sob certas condições (brandas) na função de ativação [^3]. Os resultados nesta seção são baseados em [130], e para as provas seguimos os argumentos naquele artigo [^3].

Primeiro introduzimos notação para o conjunto de todas as funções realizadas por certas arquiteturas [^3].

**Definição 3.6:** Sejam $d, m, L, n \in \mathbb{N}$ e $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ [^3]. O conjunto de todas as funções realizadas por redes neurais com entrada $d$-dimensional, saída $m$-dimensional, profundidade no máximo $L$, largura no máximo $n$, e função de ativação $\sigma$ é denotado por [^3]:

$$\
\mathcal{N}_d(\sigma; L, n) := \\{\Phi: \mathbb{R}^d \rightarrow \mathbb{R}^m \mid \Phi \text{ como na Def. 2.1, depth}(\Phi) \leq L, \text{ width}(\Phi) \leq n\\}
$$

Além disso [^3],
$$\
\mathcal{N}_d(\sigma; L) := \bigcup_{n \in \mathbb{N}} \mathcal{N}_d(\sigma; L, n)
$$

No que segue, exigimos que a função de ativação $\sigma$ pertença ao conjunto de funções contínuas por partes e localmente limitadas [^3]:

$$\
\mathcal{M} := \\{\sigma \in L_{loc}^\infty(\mathbb{R}) \mid \text{ existem intervalos } I_1, ..., I_M \text{ particionando } \mathbb{R}, \text{ s.t. } \sigma \in C^0(I_j) \text{ para todo } j = 1, ..., M\\} \quad (3.1.1)
$$

Aqui, $M \in \mathbb{N}$ é finito, e os intervalos $I_j$ são entendidos como tendo medida de Lebesgue positiva (possivelmente infinita), i.e., $I_j$ não pode ser vazio ou um único ponto [^3]. Portanto, $\sigma$ é uma função contínua por partes, e tem descontinuidades no máximo em um número finito de pontos [^3].

**Exemplo 3.7:** Funções de ativação pertencendo a $\mathcal{M}$ incluem, em particular, todas as funções contínuas não-polinomiais, o que por sua vez inclui todas as funções de ativação praticamente relevantes como a ReLU, a SiLU, e a Sigmoid discutidas na Seção 2.3 [^3]. Nesses casos, podemos escolher $M = 1$ e $I_1 = \mathbb{R}$ [^3]. Funções descontínuas incluem por exemplo a função de Heaviside $x \mapsto \mathbb{1}_{x>0}$ (também chamada de "perceptron" nesse contexto) mas também $x \mapsto \mathbb{1}_{x>0} \sin(1/x)$ [^3]: ambas pertencem a $\mathcal{M}$ com $M = 2$, $I_1 = (-\infty, 0]$ e $I_2 = (0, \infty)$ [^3]. Excluímos por exemplo a função $x \mapsto 1/x$, que não é localmente limitada [^3].

O restante desta subseção é dedicado a provar o seguinte teorema que já foi anunciado repetidamente [^3].

**Teorema 3.8:** Seja $d \in \mathbb{N}$ e $\sigma \in \mathcal{M}$ [^3]. Então $\overline{\mathcal{N}_d(\sigma; 1)}$ é um aproximador universal de $C^0(\mathbb{R}^d)$ se e somente se $\sigma$ não é um polinômio [^3].

**Observação 3.9:** Veremos no Exercício 3.26 e no Corolário 3.18 que redes neurais também podem aproximar arbitrariamente bem funções não-contínuas com respeito a normas adequadas [^4].

O teorema da aproximação universal por Leshno, Lin, Pinkus e Schocken [130]—do qual o Teorema 3.8 é um caso especial—é até mesmo formulado para um conjunto $\mathcal{M}$ muito maior, que permite funções de ativação que têm descontinuidades em um conjunto (possivelmente não-finito) de medida de Lebesgue zero [^4]. Em vez de provar o teorema nessa generalidade, recorremos ao caso mais simples declarado acima [^4]. Isso permite evitar algumas tecnicidades, mas as principais ideias permanecem as mesmas [^4]. A estratégia de prova é verificar as seguintes três afirmações [^4]:
(i) se $C^0(\mathbb{R}^1) \subseteq \overline{\mathcal{N}_1(\sigma; 1)}$, então $C^0(\mathbb{R}^d) \subseteq \overline{\mathcal{N}_d(\sigma; 1)}$ [^4],
(ii) se $\sigma \in C^\infty(\mathbb{R})$ não é um polinômio, então $C^0(\mathbb{R}^1) \subseteq \overline{\mathcal{N}_1(\sigma; 1)}$ [^4],
(iii) se $\sigma \in \mathcal{M}$ não é um polinômio, então existe $\tilde{\sigma} \in C^\infty(\mathbb{R}) \cap \overline{\mathcal{N}_1(\sigma; 1)}$ que não é um polinômio [^4].

Ao observar que $\tilde{\sigma} \in \overline{\mathcal{N}_1(\sigma; 1)}$ implica $\mathcal{N}_1(\tilde{\sigma}, 1) \subseteq \overline{\mathcal{N}_1(\sigma; 1)}$, é fácil ver que essas afirmações junto com a Proposição 3.3 estabelecem a implicação "$\Leftarrow$" afirmada no Teorema 3.8 [^4]. A direção inversa é direta de verificar e será o conteúdo do Exercício 3.23 [^4].

Começamos com uma versão mais geral de (i) e reduzimos o problema para o caso unidimensional [^4].

**Lema 3.10:** Assuma que $\mathcal{H}$ é um aproximador universal de $C^0(\mathbb{R})$ [^4]. Então para todo $d \in \mathbb{N}$ [^4],

$$\
\text{span}\\{x \mapsto g(w \cdot x) \mid w \in \mathbb{R}^d, g \in \mathcal{H}\\}
$$
é um aproximador universal de $C^0(\mathbb{R}^d)$ [^4].

*Prova:* Para $k \in \mathbb{N}_0$, denotamos por $\mathcal{H}_k$ o espaço de todos os polinômios homogêneos de grau $k$, isto é [^4],

$$\
\mathcal{H}_k := \text{span}\\{\mathbb{R}^d \ni x \mapsto x^\alpha \mid \alpha \in \mathbb{N}^d, |\alpha| = k\\}
$$

Afirmamos que [^4]

$$\
\mathcal{H}_k \subseteq \text{span}\\{\mathbb{R}^d \ni x \mapsto g(w \cdot x) \mid w \in \mathbb{R}^d, g \in \mathcal{H}\\} =: \mathcal{X} \quad (3.1.2)
$$

para todo $k \in \mathbb{N}_0$ [^4]. Isso implica que todos os polinômios multivariados pertencem a $\mathcal{X}$ [^4]. Uma aplicação do teorema de Stone-Weierstrass (cp. Exemplo 3.5) e da Proposição 3.3 então conclui a prova [^4].

Para todo $\alpha, \beta \in \mathbb{N}^d$ com $|\alpha| = |\beta| = k$, vale $D^\beta x^\alpha = \delta_{\beta, \alpha} \alpha!$, onde $\alpha! := \prod_{i=1}^d \alpha_i!$ e $\delta_{\beta, \alpha} = 1$ se $\beta = \alpha$ e $\delta_{\beta, \alpha} = 0$ caso contrário [^4]. Portanto, como $\\{x \mapsto x^\alpha \mid |\alpha| = k\\}$ é uma base de $\mathcal{H}_k$, o conjunto $\\{D^\alpha \mid |\alpha| = k\\}$ é uma base de seu dual topológico $\mathcal{H}_k\'$ [^4]. Assim, cada funcional linear $l \in \mathcal{H}_k\'$ permite a representação $l = p(D)$ para algum $p \in \mathcal{H}_k$ (aqui $D$ representa o diferencial) [^4].

Pela fórmula multinomial [^4]

$$\
(w \cdot x)^k = \left(\sum_{j=1}^d w_j x_j\right)^k = \sum_{\\{\alpha \in \mathbb{N}^d \mid |\alpha| = k\\}} \frac{k!}{\alpha!} w^\alpha x^\alpha
$$

Portanto, temos que $(x \mapsto (w \cdot x)^k) \in \mathcal{H}_k$ [^5]. Além disso, para todo $l = p(D) \in \mathcal{H}_k\'$ e todo $w \in \mathbb{R}^d$ temos que [^5]

$$\
l(x \mapsto (w \cdot x)^k) = p(D)(x \mapsto (w \cdot x)^k) = k! p(w)
$$

Portanto, se $l(x \mapsto (w \cdot x)^k) = p(D)(x \mapsto (w \cdot x)^k) = 0$ para todo $w \in \mathbb{R}^d$, então $p = 0$ e assim $l = 0$ [^5]. Isso implica $\text{span}\\{x \mapsto (w \cdot x)^k \mid w \in \mathbb{R}^d\\} = \mathcal{H}_k$ [^5]. De fato, se existe $h \in \mathcal{H}_k$ que não está em $\text{span}\\{x \mapsto (w \cdot x)^k \mid w \in \mathbb{R}^d\\}$, então pelo teorema de Hahn-Banach (veja Teorema B.8), existe um funcional não-zero em $\mathcal{H}_k\'$ anulando em $\text{span}\\{x \mapsto (w \cdot x)^k \mid w \in \mathbb{R}^d\\}$ [^5]. Isso contradiz a observação anterior [^5].

Pela universalidade de $\mathcal{H}$ não é difícil ver que $x \mapsto (w \cdot x)^k \in \mathcal{X}$ para todo $w \in \mathbb{R}^d$ [^5]. Portanto, temos $\mathcal{H}_k \subseteq \mathcal{X}$ para todo $k \in \mathbb{N}_0$ [^5]. $\blacksquare$

Pelo lema acima, para verificar que $\overline{\mathcal{N}_d(\sigma; 1)}$ é um aproximador universal, é suficiente mostrar que $\overline{\mathcal{N}_1(\sigma; 1)}$ é um aproximador universal [^5]. Primeiro mostramos que este é o caso para ativações sigmoidais [^5].

**Definição 3.11:** Uma função de ativação $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ é chamada de sigmoidal, se $\sigma \in C^0(\mathbb{R})$, $\lim_{x \rightarrow \infty} \sigma(x) = 1$ e $\lim_{x \rightarrow -\infty} \sigma(x) = 0$ [^5].

Para funções de ativação sigmoidais podemos agora concluir a universalidade no caso univariado [^5].

**Lema 3.12:** Seja $\sigma: \mathbb{R} \rightarrow \mathbb{R}$ monotonicamente crescente e sigmoidal [^5]. Então $C^0(\mathbb{R}) \subseteq \overline{\mathcal{N}_1(\sigma; 1)}$ [^5].

Provamos o Lema 3.12 no Exercício 3.24 [^5]. O Lema 3.10 e o Lema 3.12 mostram o Teorema 3.8 no caso especial onde $\sigma$ é monotonicamente crescente e sigmoidal [^5]. Para o caso geral, vamos continuar com (ii) e considerar ativações $C^\infty$ [^5].

**Lema 3.13:** Se $\sigma \in C^\infty(\mathbb{R})$ e $\sigma$ não é um polinômio, então $\mathcal{N}_1(\sigma; 1)$ é denso em $C^0(\mathbb{R})$ [^5].

*Prova:* Denotamos $\mathcal{X} := \mathcal{N}_1(\sigma; 1)$ [^5]. Mostramos novamente que todos os polinômios pertencem a $\mathcal{X}$ [^5]. Uma aplicação do teorema de Stone-Weierstrass então dá a afirmação [^5].

Fixe $b \in \mathbb{R}$ e denote $f_x(w) := \sigma(wx + b)$ para todo $x, w \in \mathbb{R}$ [^5]. Pelo teorema de Taylor, para $h \neq 0$ [^5]

$$\
\frac{\sigma((w + h)x + b) - \sigma(wx + b)}{h} = \frac{f_x(w + h) - f_x(w)}{h} = f_x\'(w) + \frac{h}{2} f_x\'\'(\xi) = f_x\'(w) + \frac{h}{2} x^2 \sigma\'\'(\xi x + b) \quad (3.1.3)
$$

para algum $\xi = \xi(h)$ entre $w$ e $w + h$ [^6]. Note que o lado esquerdo pertence a $\mathcal{N}_1(\sigma; 1)$ como uma função de $x$ [^6]. Como $\sigma\'\' \in C^0(\mathbb{R})$, para todo conjunto compacto $K \subset \mathbb{R}$ [^6]

$$\
\sup_{x \in K} \sup_{|h| \leq 1} |x^2 \sigma\'\'(\xi(h) x + b)| \leq \sup_{x \in K} \sup_{\eta \in [w-1, w+1]} |x^2 \sigma\'\'(\eta x + b)| < \infty
$$

Fazendo $h \rightarrow 0$, como uma função de $x$ o termo em (3.1.3) assim converge uniformemente para $K \ni x \mapsto f_x\'(w)$ [^6]. Como $K$ foi arbitrário, $x \mapsto f_x\'(w)$ pertence a $\mathcal{X}$ [^6]. Aplicando indutivamente o mesmo argumento para $f_x^{(k-1)} \mapsto f_x^{(k)}(w)$, encontramos que $x \mapsto f_x^{(k)}(w)$ pertence a $\mathcal{X}$ para todo $k \in \mathbb{N}$, $w \in \mathbb{R}$ [^6]. Observe que $f_x^{(k)}(w) = x^k \sigma^{(k)}(wx + b)$ [^6]. Como $\sigma$ não é um polinômio, para cada $k \in \mathbb{N}$ existe $b_k \in \mathbb{R}$ tal que $\sigma^{(k)}(b_k) \neq 0$ [^6]. Escolhendo $w = 0$, obtemos que $x \mapsto x^k$ pertence a $\mathcal{X}$ [^6]. $\blacksquare$

Finalmente, chegamos à prova de (iii)—a afirmação de que existe pelo menos uma função $C^\infty(\mathbb{R})$ não-polinomial no fecho de $\mathcal{N}_1(\sigma; 1)$ [^6]. O argumento é dividido em dois lemas [^6]. Denotamos no seguinte por $C_c^\infty(\mathbb{R})$ o conjunto de funções $C^\infty(\mathbb{R})$ com suporte compacto [^6].

**Lema 3.14:** Seja $\sigma \in \mathcal{M}$ [^6]. Então para cada $\varphi \in C_c^\infty(\mathbb{R})$ vale $\sigma * \varphi \in \overline{\mathcal{N}_1(\sigma; 1)}$ [^6].

*Prova:* Fixe $\varphi \in C_c^\infty(\mathbb{R})$ e seja $a > 0$ tal que $\text{supp} \varphi \subseteq [-a, a]$ [^6]. Temos [^6]

$$\
\sigma * \varphi(x) = \int_\mathbb{R} \sigma(x - y) \varphi(y) dy
$$

Denotamos $y_j := -a + 2aj/n$ para $j = 0, ..., n$ e definimos para $x \in \mathbb{R}$ [^6]

$$\
f_n(x) := \frac{2a}{n} \sum_{j=0}^{n-1} \sigma(x - y_j) \varphi(y_j)
$$

Claramente, $f_n \in \mathcal{N}_1(\sigma; 1)$ [^6]. Mostraremos $f_n \xrightarrow{CC} \sigma * \varphi$ as $n \rightarrow \infty$ [^6]. Para fazer isso verificamos a convergência uniforme de $f_n$ para $\sigma * \varphi$ no intervalo $[-b, b]$ com $b > 0$ arbitrário mas fixo [^6].

Para $x \in [-b, b]$ [^6]

$$\
|\sigma * \varphi(x) - f_n(x)| = \left| \int_\mathbb{R} \sigma(x - y) \varphi(y) dy - \frac{2a}{n} \sum_{j=0}^{n-1} \sigma(x - y_j) \varphi(y_j) \right| = \left| \sum_{j=0}^{n-1} \int_{y_j}^{y_{j+1}} \sigma(x - y) \varphi(y) - \sigma(x - y_j) \varphi(y_j) dy \right| \quad (3.1.4)
$$

Fixe $\varepsilon \in (0, 1)$ [^7]. Como $\sigma \in \mathcal{M}$, existem $z_1, ..., z_M \in \mathbb{R}$ tal que $\sigma$ é contínua em $\mathbb{R} \setminus \\{z_1, ..., z_M\\}$ (cp. (3.1.1)) [^7]. Com $D_\varepsilon := \bigcup_{i=1}^M (z_i - \varepsilon, z_i + \varepsilon)$, observe que $\sigma$ é uniformemente contínua no conjunto compacto $K_\varepsilon := [-a - b, a + b] \cap D_\varepsilon^c$ [^7]. Agora seja $J_c \cup J_d = \\{0, ..., n - 1\\}$ uma partição (dependendo de $x$), tal que $j \in J_c$ se e somente se $[x - y_{j+1}, x - y_j] \subseteq K_\varepsilon$ [^7]. Portanto, $j \in J_d$ implica a existência de $i \in \\{1, ..., M\\}$ tal que a distância de $z_i$ para $[x - y_{j+1}, x - y_j]$ é no máximo $\varepsilon$ [^7]. Devido ao intervalo $[x - y_{j+1}, x - y_j]$ tendo comprimento $2a/n$, podemos limitar [^7]

$$\
\sum_{j \in J_d} |y_{j+1} - y_j| = \left| \bigcup_{j \in J_d} [x - y_{j+1}, x - y_j] \right| \leq \left| \bigcup_{i=1}^M (z_i - \varepsilon, z_i + \varepsilon) \cup \left( z_i - \varepsilon - \frac{2a}{n}, z_i + \varepsilon + \frac{2a}{n} \right) \right| \leq M \cdot \left( 2\varepsilon + \frac{4a}{n} \right)
$$

Em seguida, devido à limitação local de $\sigma$ e ao fato de que $\varphi \in C_c^\infty$, vale $\sup_{|y| \leq a + b} |\sigma(y)| + \sup_{|y| \leq a} |\varphi(y)| =: \gamma < \infty$ [^7]. Portanto [^7],

$$\
|\sigma * \varphi(x) - f_n(x)| = \left| \sum_{j \in J_c \cup J_d} \int_{y_j}^{y_{j+1}} \sigma(x - y) \varphi(y) - \sigma(x - y_j) \varphi(y_j) dy \right| \leq \sum_{j \in J_c \cup J_d} \int_{y_j}^{y_{j+1}} |\sigma(x - y) \varphi(y) - \sigma(x - y_j) \varphi(y_j)| dy
$$

$$\
\leq 2 \gamma^2 M \cdot \left( 2\varepsilon + \frac{4a}{n} \right) + 2a \sup_{j \in J_c} \sup_{y \in [y_j, y_{j+1}]} |\sigma(x - y) \varphi(y) - \sigma(x - y_j) \varphi(y_j)| \quad (3.1.5)
$$

Podemos limitar o termo no último máximo por [^7]

$$\
|\sigma(x - y) \varphi(y) - \sigma(x - y_j) \varphi(y_j)| \leq |\sigma(x - y) - \sigma(x - y_j)| |\varphi(y)| + |\sigma(x - y_j)| |\varphi(y) - \varphi(y_j)| \leq \gamma \left( \sup_{\substack{z_1, z_2 \in K_\varepsilon \\\\ |z_1 - z_2| \leq 2a/n}} |\sigma(z_1) - \sigma(z_2)| + \sup_{\substack{z_1, z_2 \in [-a, a] \\\\ |z_1 - z_2| \leq 2a/n}} |\varphi(z_1) - \varphi(z_2)| \right)
$$

Finalmente, a continuidade uniforme de $\sigma$ em $K_\varepsilon$ e de $\varphi$ em $[-a, a]$ implica que o último termo tende a 0 quando $n \rightarrow \infty$ uniformemente para todo $x \in [-b, b]$ [^8]. Isso mostra que existe $C < \infty$ (independente de $\varepsilon$ e $x$) e $n_\varepsilon \in \mathbb{N}$ (independente de $x$) tal que o termo em (3.1.5) é limitado por $C \varepsilon$ para todo $n \geq n_\varepsilon$ [^8]. Como $\varepsilon$ foi arbitrário, isso produz a afirmação [^8]. $\blacksquare$

**Lema 3.15:** Se $\sigma \in \mathcal{M}$ e $\sigma * \varphi$ é um polinômio para todo $\varphi \in C_c^\infty(\mathbb{R})$, então $\sigma$ é um polinômio [^8].

*Prova:* Fixe $-\infty < a < b < \infty$ e considere $C^\infty(a, b) := \\{\varphi \in C^\infty(\mathbb{R}) \mid \text{supp} \varphi \subseteq [a, b]\\}$ [^8]. Defina uma métrica $\rho$ em $C^\infty(a, b)$ via [^8]

$$\
\rho(\varphi, \psi) := \sum_{j \in \mathbb{N}_0} \frac{2^{-j} |\varphi - \psi|_{C^j(a, b)}}{1 + |\varphi - \psi|_{C^j(a, b)}}
$$
onde [^8]

$$\
|\varphi|_{C^j(a, b)} := \sup_{x \in [a, b]} |\varphi^{(j)}(x)|
$$

Como o espaço de funções $j$ vezes diferenciáveis em $[a, b]$ é completo com respeito à norma $\sum_{i=0}^j |\varphi|_{C^i(a, b)}$, veja por exemplo [88, Satz 104.3], o espaço $C^\infty(a, b)$ é completo com a métrica $\rho$ [^8]. Para $k \in \mathbb{N}$ defina [^8]

$$\
V_k := \\{\varphi \in C^\infty(a, b) \mid \sigma * \varphi \in P_k\\}
$$
onde $P_k := \text{span}\\{\mathbb{R} \ni x \mapsto x^i \mid 0 \leq j \leq k\\}$ denota o espaço de polinômios de grau no máximo $k$ [^8]. Então $V_k$ é fechado com respeito à métrica $\rho$ [^8]. Para ver isso, só precisamos observar que para uma sequência convergente $\varphi_j \rightarrow \varphi_*$ com respeito a $\rho$ e $\varphi_j \in V_k$, segue que $D^{k+1}(\sigma * \varphi_*) = 0$ e portanto $\sigma * \varphi_*$ é um polinômio [^8]. Como $D^{k+1}(\sigma * \varphi_j) = 0$ computamos com a linearidade da convolução e o fato de que $D^{k+1}(f * g) = f * D^{k+1}(g)$ para $g$ diferenciável e se ambos os lados são bem definidos que [^8]

$$\
\sup_{x \in [a, b]} |D^{k+1}(\sigma * \varphi_*)(x)| = \sup_{x \in [a, b]} |\sigma * D^{k+1}(\varphi_* - \varphi_j)(x)| \leq (b - a) \sup_{z \in [a-b, b-a]} |\sigma(z)| \cdot \sup_{x \in [a, b]} |D^{k+1}(\\