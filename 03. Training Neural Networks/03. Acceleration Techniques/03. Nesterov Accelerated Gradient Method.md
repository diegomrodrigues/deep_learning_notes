## Nesterov's Accelerated Gradient Method

### Introdução
Em continuidade às técnicas de aceleração para otimização, este capítulo explora o método do **gradiente acelerado de Nesterov (NAG)**, uma evolução do método da "heavy ball" [^178, 158, 157]. Anteriormente, discutimos o método do gradiente descendente e suas propriedades de convergência, principalmente sob as condições de *L-smoothness* e convexidade forte. O NAG, ao avaliar o gradiente em uma estimativa da posição na próxima iteração, busca melhorar as taxas de convergência, especialmente para funções objetivo *L-smooth* e $\mu$-fortemente convexas [^1]. Este capítulo detalha o NAG, fornecendo uma análise de sua formulação, propriedades de convergência e comparação com outros métodos.

### Conceitos Fundamentais

O método da "heavy ball" introduz um termo de momento para acelerar a convergência do gradiente descendente [^178]. NAG refina essa abordagem, alterando o ponto em que o gradiente é avaliado. A formulação do NAG é dada por [^1]:
$$\
\begin{aligned}
v_{k+1} &= w_k - \alpha \nabla f(w_k) \\
w_{k+1} &= v_{k+1} + \beta (v_{k+1} - v_k),
\end{aligned}
$$
onde:
- $v_{k+1}$ representa uma atualização intermediária da posição.
- $w_k$ é uma estimativa da posição na iteração $k$.
- $\alpha > 0$ é o tamanho do passo (learning rate).
- $\beta \in (0, 1)$ é o coeficiente de momento.
- $\nabla f(w_k)$ é o gradiente da função objetivo $f$ avaliado em $w_k$.

A principal diferença entre o NAG e o método da "heavy ball" é que, no NAG, o gradiente é avaliado em $w_k = v_k + \beta(v_k - v_{k-1})$ [^1]. Isso pode ser interpretado como avaliar o gradiente em uma estimativa da posição na próxima iteração.

Sob condições de *L-smoothness* e $\mu$-forte convexidade, o NAG alcança uma taxa de convergência de $1 - \kappa^{-1/2}$, onde $\kappa = L/\mu$ é o número de condição da função objetivo [^1]. Além disso, o erro na função objetivo decai da seguinte forma [^1]:
$$\
f(v_k) - f(w^*) \leq \left(1 - \sqrt{\frac{\mu}{L}}\right)^k \left(f(v_0) - f(w^*) + \frac{\mu}{2} ||u_0 - w^*||^2\right),
$$
onde $w^*$ é o minimizador da função objetivo $f$.

Para analisar a convergência, é útil reescrever o NAG como uma atualização de três sequências [^1]:
$$\
\begin{aligned}\nu_0 &= \frac{(1 + \tau)w_0 - v_0}{\tau} \\
w_k &= \frac{\tau}{1 + \tau} u_k + \frac{1}{1 + \tau} v_k \\
\nu_{k+1} &= w_k - \frac{1}{L} \nabla f(w_k) \\
v_{k+1} &= v_k + \tau \cdot (w_k - u_k) - \frac{\tau}{L} \nabla f(w_k),
\end{aligned}
$$
onde $\tau = \sqrt{\mu/L}$, $\alpha = 1/L$, e $\beta = (1 - \tau)/(1 + \tau)$ [^1].

**Teorema da Convergência:** Sob as condições de *L-smoothness* e $\mu$-forte convexidade, e com $\tau = \sqrt{\mu/L}$, o NAG satisfaz [^1]:
$$\
||u_k - w^*||^2 \leq \left(1 - \sqrt{\frac{\mu}{L}}\right)^k \left(||u_0 - w^*||^2 + \frac{4}{\mu} (f(v_0) - f(w^*))\right),
$$
$$\
f(v_k) - f(w^*) \leq \left(1 - \sqrt{\frac{\mu}{L}}\right)^k \left(\frac{\mu}{2} ||u_0 - w^*||^2 + f(v_0) - f(w^*)\right).
$$

### Conclusão
O método do gradiente acelerado de Nesterov (NAG) representa uma melhoria significativa em relação ao método da "heavy ball" e ao gradiente descendente padrão [^1]. Ao avaliar o gradiente em uma estimativa da próxima posição, o NAG alcança taxas de convergência mais rápidas, especialmente para funções objetivo *L-smooth* e $\mu$-fortemente convexas. A análise detalhada apresentada neste capítulo fornece uma base sólida para compreender e aplicar o NAG em problemas de otimização complexos, como o treinamento de redes neurais. Enquanto o gradiente descendente tem uma taxa de convergência de $1 - \kappa^{-1}$, o NAG tem uma taxa de $1 - \kappa^{-1/2}$ [^1]. Isso implica que o NAG é particularmente vantajoso para problemas mal condicionados (onde $\kappa$ é grande).

### Referências
[^1]: Capítulo 10 do texto fornecido.

<!-- END -->