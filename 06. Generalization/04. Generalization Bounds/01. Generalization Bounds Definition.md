## Generalization Bounds: Formal Definition and Implications

### Introdução
No contexto de aprendizado de máquina, a capacidade de um modelo generalizar bem para dados não vistos é crucial. Como discutido anteriormente [^4], um dos aspectos para garantir o sucesso do aprendizado é limitar o erro de generalização ($\epsilon_{gen}$). Este capítulo se concentra na formalização e nas implicações dos **limites de generalização**, que fornecem garantias teóricas sobre o desempenho de um modelo em dados não vistos, com base em seu desempenho nos dados de treinamento.

### Conceitos Fundamentais

Um **limite de generalização** é definido como uma função $\kappa(\delta, m)$ que fornece um limite superior para a discrepância entre o **risco verdadeiro** $R(h)$ e o **risco empírico** $R_S(h)$ para todas as hipóteses $h$ em um conjunto de hipóteses $H$, com probabilidade de pelo menos $1 - \delta$ sobre a amostra aleatória $S$ [^5]. Formalmente, isso é expresso como:

$$\
P\left(\sup_{h \in H} |R(h) - R_S(h)| \leq \kappa(\delta, m)\right) \geq 1 - \delta
$$

onde:
*   $R(h) = \mathbb{E}_{(x,y) \sim D}[L(h(x), y)]$ é o risco verdadeiro de $h$, ou seja, a expectativa da função de perda $L$ sobre a distribuição de dados $D$ [^2].
*   $R_S(h) = \frac{1}{m} \sum_{i=1}^{m} L(h(x_i), y_i)$ é o risco empírico de $h$ na amostra $S = \{(x_i, y_i)\}_{i=1}^{m}$ [^3].
*   $H$ é o conjunto de hipóteses considerado [^3].
*   $m$ é o tamanho da amostra $S$ [^3].
*   $\delta$ é o nível de confiança (ou tolerância ao erro), com $0 < \delta < 1$ [^5].
*   $\kappa(\delta, m)$ é o limite de generalização, uma função que depende de $\delta$ e $m$ [^5].

O objetivo dos limites de generalização é garantir que o risco empírico convirja para o risco verdadeiro à medida que o tamanho da amostra aumenta, o que é tipicamente alcançado através de **desigualdades de concentração** [^5]. Desigualdades de concentração, como a desigualdade de Hoeffding [^5], quantificam a probabilidade de uma variável aleatória se desviar de seu valor esperado.

**Definição 14.6 (Generalização bound)** [^5]. Seja $H \subseteq \{h: X \rightarrow Y\}$ um conjunto de hipóteses, e seja $L: Y \times Y \rightarrow \mathbb{R}$ uma função de perda. Seja $\kappa: (0, 1) \times \mathbb{N} \rightarrow \mathbb{R}^+$ tal que para todo $\delta \in (0, 1)$, temos $\kappa(\delta, m) \rightarrow 0$ para $m \rightarrow \infty$. Chamamos $\kappa$ de um *generalization bound* para $H$ se para toda distribuição $D$ em $X \times Y$, todo $m \in \mathbb{N}$ e todo $\delta \in (0, 1)$, vale com probabilidade de pelo menos $1 - \delta$ sobre a amostra aleatória $S \sim D^m$ que
$$
\sup_{h \in H} |R(h) - R_S(h)| \leq \kappa(\delta, m).
$$

**Observação 14.7** [^5]. Para um *generalization bound* $\kappa$, vale que
$$
P[R(h_S) - R_S(h_S) \leq \epsilon] \geq 1 - \delta
$$
assim que $m$ é tão grande que $\kappa(\delta, m) \leq \epsilon$. Se existe um minimizador de risco empírico $h_S$ tal que $R_S(h_S) = 0$, então com alta probabilidade o minimizador de risco empírico também terá um pequeno risco $R(h_S)$. A minimização de risco empírico é frequentemente referida como um algoritmo "PAC", que significa *probably approximately correct*.

Um aspecto importante é que a definição 14.6 requer que o limite superior $\kappa$ na discrepância entre o risco empírico e o risco seja independente da distribuição $D$ [^5].

**Exemplo 14.8 (Generalização no problema de qualidade do café)** [^5]. No Exemplo 14.1, a distribuição subjacente descreve tanto o nosso processo de escolha de cafés quanto a relação entre os atributos e a qualidade. Suponha que não gostamos de beber café que custa menos de 1€. Consequentemente, não temos uma única amostra de tal café no conjunto de dados e, portanto, não temos chance de aprender sobre a qualidade de cafés baratos. No entanto, a ausência de amostras de café que custam menos de 1€ no nosso conjunto de dados deve-se à nossa aversão geral a tal café. Como resultado, corremos um baixo risco de classificar incorretamente a qualidade de um café que é mais barato que 1€, pois é improvável que escolhamos tal café no futuro.

### Generalização bounds e desigualdades de concentração

Para estabelecer os limites de generalização, usamos ferramentas estocásticas que garantem que o risco empírico convirja para o risco verdadeiro à medida que o tamanho da amostra aumenta [^5]. Isso é tipicamente alcançado através de desigualdades de concentração. Uma das mais simples e bem conhecidas é a desigualdade de Hoeffding.

**Proposição 14.9 (Finite hypothesis set)** [^6]. Seja $H \subseteq \{h: X \rightarrow Y\}$ um conjunto de hipóteses finito. Seja $L: Y \times Y \rightarrow \mathbb{R}$ tal que $L(Y \times Y) \subseteq [c_1, c_2]$ com $c_2 - c_1 = C > 0$.
Então, para todo $m \in \mathbb{N}$ e toda distribuição $D$ em $X \times Y$, vale com probabilidade de pelo menos $1 - \delta$ sobre a amostra $S \sim D^m$ que
$$
\sup_{h \in H} |R(h) - R_S(h)| \leq C \sqrt{\frac{\log(|H|) + \log(2/\delta)}{2m}}
$$

### Conclusão

Os limites de generalização fornecem uma estrutura teórica para entender e controlar o desempenho de modelos de aprendizado de máquina. Ao garantir que o risco empírico convirja para o risco verdadeiro, podemos ter maior confiança na capacidade de um modelo generalizar bem para dados não vistos. A escolha de um conjunto de hipóteses $H$ que minimize tanto o erro de aproximação (aproximação) quanto o erro de generalização (Egen) é um desafio central no aprendizado de máquina, conforme discutido nas seções subsequentes [^4].

### Referências
[^1]: Página 1, Capítulo 14
[^2]: Página 2, Definição 14.2
[^3]: Página 3, Definição 14.4
[^4]: Página 4
[^5]: Página 5
[^6]: Página 6
<!-- END -->