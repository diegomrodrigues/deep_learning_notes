## Empirical Risk Minimization: Approximation of True Risk
### Introdução
Como discutido anteriormente [^1], o aprendizado geralmente se baseia em um conjunto de dados finito. O objetivo é encontrar uma função que generalize bem para dados não vistos. No contexto de redes neurais profundas, a minimização do risco empírico (ERM) é uma técnica fundamental. Dado que o risco verdadeiro $R(h)$ não pode ser avaliado para funções de perda não triviais devido à distribuição desconhecida $D$, utiliza-se uma amostra *i.i.d.* de *m* observações extraídas de *D* para aproximar o risco [^3]. Este capítulo explora a minimização do risco empírico como uma aproximação do risco verdadeiro, detalhando os conceitos e desafios associados a essa técnica.

### Conceitos Fundamentais
A minimização do risco empírico (ERM) é uma estratégia utilizada quando a distribuição de probabilidade subjacente, $D$, é desconhecida [^3]. O **risco empírico** $R_S(h)$ é definido como a perda média sobre a amostra $S$ [^3]:
$$ R_S(h) = \frac{1}{m} \sum_{i=1}^{m} L(h(x_i), y_i) $$
onde $L$ é a função de perda, $(x_i, y_i)$ são os pares de dados na amostra $S$, e $h$ é a hipótese. O risco empírico fornece uma estimativa de quão bem uma dada hipótese $h$ se comporta sobre os dados observados e é usado como um *proxy* para o risco verdadeiro quando a distribuição subjacente é desconhecida [^3].

**Definição Formal** [^3]: Seja $H$ um conjunto de hipóteses, $L: Y \times Y \rightarrow \mathbb{R}$ uma função de perda, e $S = \{(x_i, y_i)\}_{i=1}^m$ uma amostra de $(X \times Y)^m$. Uma função $h_S \in H$ é chamada de minimizador de risco empírico se:
$$ R_S(h_S) = \inf_{h \in H} R_S(h) $$

Encontrar um minimizador do risco é um desafio considerável [^3]. Primeiro, não podemos pesquisar através de todas as funções mensuráveis. Portanto, precisamos nos restringir a um conjunto específico $H \subseteq \{h : X \rightarrow Y\}$ chamado o **conjunto de hipóteses**. Em segundo lugar, somos confrontados com o problema de que não podemos avaliar $R(h)$ para funções de perda não triviais, porque a distribuição $D$ é desconhecida [^3]. Para aproximar o risco, assumiremos o acesso a uma amostra *i.i.d.* de *m* observações extraídas de $D$ [^3].

**Estimador Não-Viciado** [^4]: Se a amostra $S$ é extraída *i.i.d.* de acordo com $D$, então, da linearidade do valor esperado, $R_S(h)$ é um estimador não-viciado de $R(h)$, ou seja, $\mathbb{E}_{S \sim D^m}[R_S(h)] = R(h)$.

A lei fraca dos grandes números afirma que a média da amostra de uma sequência *i.i.d.* de variáveis aleatórias integráveis converge em probabilidade para o valor esperado [^4]. Portanto, há alguma esperança de que, pelo menos para um $m \in \mathbb{N}$ grande, minimizar o risco empírico em vez do risco real possa levar a uma boa hipótese [^4].

### Generalização e Limites
A questão central na ERM é quão bem o risco empírico se aproxima do risco verdadeiro e, consequentemente, quão boa é a generalização do modelo [^4]. Para quantificar isso, define-se o **erro de generalização** como a diferença entre o risco verdadeiro e o risco empírico: $|R(h) - R_S(h)|$ [^4].

Uma análise da diferença entre o risco verdadeiro e o risco empírico pode ser feita através da seguinte decomposição [^4]:
$$ R(h_S) - R^* = R(h_S) - R_S(h_S) + R_S(h_S) - R^* $$
$$ \leq |R(h_S) - R_S(h_S)| + R_S(h^*) - R^* $$
$$ \leq 2 \sup_{h \in H} |R(h) - R_S(h)| + R(h^*) - R^* $$
onde $R^* = \inf_{h: X \rightarrow Y} R(h)$ é o risco de Bayes [^2], $h_S$ é o minimizador do risco empírico, e $h^*$ é uma hipótese arbitrária em $H$ [^4]. O primeiro termo, $\sup_{h \in H} |R(h) - R_S(h)|$, representa o erro de generalização, enquanto o segundo termo, $R(h^*) - R^*$, representa o erro de aproximação.

Essa decomposição leva à seguinte relação [^4]:
$$R(h_S) - R^* \leq 2 \epsilon_{gen} + \epsilon_{approx}$$
onde $\epsilon_{gen} = \sup_{h \in H} |R(h) - R_S(h)|$ é o erro de generalização e $\epsilon_{approx} = \inf_{h \in H} R(h) - R^*$ é o erro de aproximação.

Uma outra relação pode ser derivada considerando apenas (14.2.2) [^4]:
$$ R(h_S) \leq \sup_{h \in H} |R(h) - R_S(h)| + \inf_{h \in H} R_S(h) $$
$$ =: \epsilon_{gen} + \epsilon_{int} $$
onde $\epsilon_{int}$ é o erro de interpolação [^4].

Portanto, a chave para uma boa generalização é controlar o erro de generalização [^4].

### Conclusão
A minimização do risco empírico é uma técnica fundamental para o aprendizado de máquina quando a distribuição subjacente dos dados é desconhecida [^3]. Ao aproximar o risco verdadeiro com o risco empírico, podemos treinar modelos que generalizam bem para dados não vistos [^3]. No entanto, é crucial entender e controlar o erro de generalização para garantir que o modelo não esteja apenas se ajustando aos dados de treinamento, mas também capturando padrões verdadeiros que se aplicam a novos dados [^4]. As técnicas de regularização, validação cruzada e escolha cuidadosa do conjunto de hipóteses são essenciais para mitigar o sobreajuste e melhorar a capacidade de generalização dos modelos treinados com ERM [^3]. A análise do trade-off entre aproximação e complexidade é fundamental para entender o desempenho dos modelos de aprendizado de máquina, conforme discutido ao longo deste capítulo [^4].
### Referências
[^1]: Capítulo 14, página 188
[^2]: Capítulo 14, página 189
[^3]: Capítulo 14, página 190
[^4]: Capítulo 14, página 191
<!-- END -->